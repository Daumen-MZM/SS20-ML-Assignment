{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8: Neural Networks\n",
    "\n",
    "Only use the already imported library `numpy` and the Python standard library. For the evaluation you may also use scikit-learn (`sklearn`) and `matplotlib`. Make sure that the dataset `airfoil_self_noise.csv` is in the same directory as the notebook.\n",
    "\n",
    "List your team members (name and immatriculation number) and indicate whether you are a B.Sc. Data Science or other group in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yang Zheng  (3434770)\n",
    "- Yuchan Bian (3496226)\n",
    "- Zhiming Ma  (3495421)\n",
    "\n",
    "Other group, not B.Sc. Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_dataset(path):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    data = np.genfromtxt(path)\n",
    "    X, y = data[:, :5], data[:, 5]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2020)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "X_train, X_test, y_train, y_test = load_dataset('airfoil_self_noise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Feedforward Neural Network: Programming\n",
    "\n",
    "In this task, you will implement a feedforward neural network for regression. The hyperparameters of the model are:\n",
    "- `input_dim`: The dimension of the input vector.\n",
    "- `output_dim`: The dimension of the output vector.\n",
    "- `width`: The dimension of each hidden layer.\n",
    "- `depth`: The number of hidden layers. For B.Sc. Data Science students, this parameter is constant with a value of 1.\n",
    "- `learning_rate`: The learning rate for gradient descent.\n",
    "- `epochs`: The number of epochs/iterations performed during training.\n",
    "\n",
    "B.Sc. Data Science only have to implement for a single hidden layer, i.e. `depth = 1`. All other students have to implement the network for any `depth >= 1`.\n",
    "\n",
    "The activation function for each hidden layer is ReLU (g(x) = max(0, x)). The output layer uses the identity as activation, since our objective is regression.\n",
    "\n",
    "You have to implement the `FeedforwardNeuralNetworkRegressor`.\n",
    "\n",
    "The `__init__` method initializes the network.\n",
    "Initialize each weight and bias randomly with a standard Gaussian distribution using the numpy function `numpy.random.normal` with default parameters.\n",
    "\n",
    "The `fit` method trains the network.\n",
    "Use backpropagation with gradient descent similar to Task 2.\n",
    "Use the whole training data set for each training epoch.\n",
    "Use the mean squared error as loss function.\n",
    "\n",
    "The `predict` method computes the forward-pass of the network.\n",
    "\n",
    "Evaluate your classifier on the test data with the mean squared error and compare your results to your linear regression model from assignment 3. Try out different hyper-parameters and compare the results. You may want to normalize your input and output data for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNeuralNetworkClassifier(object):\n",
    "    # four methods: _init_, fit, predict, foreward\n",
    "    def __init__(self, input_dim, output_dim, width, depth, learning_rate, epochs):\n",
    "        # Add your code, such as initialization of weights here.\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.layer_params = []\n",
    "        \n",
    "        # normal distributed parameters\n",
    "        for dep in range(depth+1):\n",
    "            layer = []\n",
    "            if dep == 0:\n",
    "                weight = np.random.normal(0,1,size = (width[dep],input_dim))\n",
    "                bias = np.random.normal(0,1,size = (width[dep],1))\n",
    "            elif dep == depth:\n",
    "                weight = np.random.normal(0,1,size = (output_dim, width[dep-1]))\n",
    "                bias = np.random.normal(0,1,size = (output_dim,1))\n",
    "            else:\n",
    "                weight = np.random.normal(0,1,size = (width[dep], width[dep-1]))\n",
    "                bias = np.random.normal(0,1,size = (width[dep],1))\n",
    "                \n",
    "            layer.append(weight)\n",
    "            layer.append(bias)\n",
    "            self.layer_params.append(layer)\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        losses = np.zeros(self.epochs)\n",
    "        loss_accum = 0\n",
    "        data_length = X.shape[0]\n",
    "        \n",
    "        #normalization\n",
    "        mu = np.mean(X,axis=0)\n",
    "        dev = np.sqrt(np.var(X,axis=0))\n",
    "        \n",
    "        for ep in range(self.epochs):\n",
    "            print('epoch:',ep)\n",
    "            \n",
    "            #foreward       \n",
    "            X_0 = (X.copy() - mu* np.ones((X.shape[0],X.shape[1])))/dev\n",
    "            \n",
    "            X_0 = np.transpose(X_0)\n",
    "            \n",
    "            y_pred, tempXs, loss = self.foreward(X_0[:,0], y[0])\n",
    "            \n",
    "            loss_accum = loss_accum + loss\n",
    "            #losses.append(loss)\n",
    "\n",
    "            # Slide Page 63\n",
    "            for num in range(data_length):\n",
    "                #dL_dy_pred_i\n",
    "                step = 2 * (y_pred - y[num])/data_length\n",
    "            \n",
    "                #back propagation\n",
    "                for dep in reversed(range(self.depth+1)):\n",
    "                    phi = tempXs[dep].copy()\n",
    "            \n",
    "                    #derivative of ReLU\n",
    "                    phi[phi>0] = 1\n",
    "                    phi[phi<=0] = 0\n",
    "\n",
    "                    step = step * phi\n",
    "                    \n",
    "                    #step of b\n",
    "                    step_b = step\n",
    "                    \n",
    "                    #step of W\n",
    "                    if dep == 0:\n",
    "                        step_w = np.dot(step, X_0[:,num].reshape((1,-1)))\n",
    "                    else:\n",
    "                        step_w = np.dot(step, tempXs[dep-1].T)\n",
    "                    \n",
    "                    step = np.dot(self.layer_params[dep][0].T,step)\n",
    "                    \n",
    "                    self.layer_params[dep][0] = self.layer_params[dep][0] - self.learning_rate * step_w\n",
    "                    self.layer_params[dep][1] = self.layer_params[dep][1] - self.learning_rate * step_b\n",
    "                \n",
    "                if num != data_length-1:\n",
    "                    y_pred, tempXs, loss = self.foreward(X_0[:,num+1], y[num+1])\n",
    "                    loss_accum = loss_accum + loss\n",
    "                    \n",
    "            losses[ep] = loss_accum/data_length\n",
    "            loss_accum = 0\n",
    "                    \n",
    "        return losses\n",
    "            \n",
    "    def predict(self, X):\n",
    "        mu = np.mean(X,axis=0)\n",
    "        dev = np.sqrt(np.var(X,axis=0))\n",
    "        \n",
    "        # normalize\n",
    "        X_nor = (X.copy() - mu* np.ones((X.shape[0],X.shape[1])))/dev\n",
    "        \n",
    "        y_pred = np.zeros((X_nor.shape[0],1))\n",
    "        for num in range(X.shape[0]):\n",
    "            y, tempXs, loss = self.foreward(X_nor[num,:], 0)\n",
    "            y_pred[num] = y\n",
    "        return y_pred[:,0]\n",
    "    \n",
    "    def foreward(self, X, y):\n",
    "        \n",
    "        data_length = 1\n",
    "        tempXs = []\n",
    "        tempX = X.copy()\n",
    "        tempX = tempX.reshape((-1,1))\n",
    "        \n",
    "        for dep in range(self.depth+1):\n",
    "            activ =  np.dot(self.layer_params[dep][0],tempX) + data_length * self.layer_params[dep][1]\n",
    "            \n",
    "            #ReLU activation function\n",
    "            if dep == self.depth:\n",
    "                tempX = np.maximum(np.zeros((self.output_dim,data_length)),activ)\n",
    "            else:\n",
    "                tempX = np.maximum(np.zeros((self.width[dep],data_length)),activ)\n",
    "                \n",
    "            tempXs.append(tempX)\n",
    "            \n",
    "        if y != 0:\n",
    "            loss = (tempX - y)**2\n",
    "        else:\n",
    "            loss = 0\n",
    "        \n",
    "        return tempX, tempXs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n"
     ]
    }
   ],
   "source": [
    "# Implement your training and evaluation here.\n",
    "epoch = 10\n",
    "rate = 0.01\n",
    "\n",
    "imput_dim = X_train.shape[1]\n",
    "\n",
    "#arbitary width, can be adjusted as wished\n",
    "width = np.array([5,6,4])\n",
    "\n",
    "depth = len(width)\n",
    "myFeedforewardNNC = FeedforwardNeuralNetworkClassifier(imput_dim, 1, width, depth, rate, epoch)\n",
    "losses = myFeedforewardNNC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1844.58096793   74.17630029   42.06207885   30.98633916   26.36694568\n",
      "   23.95689753   22.71750565   21.99960002   21.52725158   21.17377058]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(losses)\n",
    "x1 = np.arange(epoch)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "line = plt.plot(x1,losses,'ro-')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error of test data is 22.16711425422826\n"
     ]
    }
   ],
   "source": [
    "y_pred = myFeedforewardNNC.predict(X_test)\n",
    "MSE = np.sum((y_pred-y_test)**2)/len(y_pred)\n",
    "print('Mean square error of test data is', MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
